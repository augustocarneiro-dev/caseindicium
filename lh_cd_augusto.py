# -*- coding: utf-8 -*-
"""LH_CD_AUGUSTO

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NCEpr88fL9iP40f7R-q-0uWSRubHzraZ

# Desafio

Você foi alocado(a) em um time da Indicium que está trabalhando atualmente junto a um cliente no processo de criação de uma plataforma de aluguéis temporários na cidade de Nova York. Para o desenvolvimento de sua estratégia de precificação, pediu para que a Indicium fizesse uma análise exploratória dos dados de seu maior concorrente, assim como um teste de validação de um modelo preditivo.

Seu objetivo é desenvolver um modelo de previsão de preços a partir do dataset oferecido, e avaliar tal modelo utilizando as métricas de avaliação que mais fazem sentido para o problema.

# Dicionário dos dados

id – Atua como uma chave exclusiva para cada anúncio nos dados do aplicativo

nome - Representa o nome do anúncio

host_id - Representa o id do usuário que hospedou o anúncio

host_name – Contém o nome do usuário que hospedou o anúncio

bairro_group - Contém o nome do bairro onde o anúncio está localizado

bairro - Contém o nome da área onde o anúncio está localizado

latitude - Contém a latitude do local

longitude - Contém a longitude do local

room_type – Contém o tipo de espaço de cada anúncio

price - Contém o preço por noite em dólares listado pelo anfitrião

minimo_noites - Contém o número mínimo de noites que o usuário deve reservar

numero_de_reviews - Contém o número de comentários dados a cada listagem

ultima_review - Contém a data da última revisão dada à listagem

reviews_por_mes - Contém o número de avaliações fornecidas por mês

calculado_host_listings_count - Contém a quantidade de listagem por host

disponibilidade_365 - Contém o número de dias em que o anúncio está disponível para reserva

# Questão 1

Faça uma análise exploratória dos dados (EDA), demonstrando as principais características entre as variáveis e apresentando algumas hipóteses de negócio relacionadas.
"""

# Importando as bibliotecas
# Pandas: biblioteca utilizada para fazer manipulações de dataframes
# Seaborn: biblioteca utilizada para análises gráficas
import pandas as pd
import seaborn as sns

# Coletando os dados
# Utilizando o Pandas para abrir o arquivo com os dados
precificacao = pd.read_csv('/content/teste_indicium_precificacao.csv')

# Analisando os dados coletados
# Visualizando arquivos da base de dados (os 5 primeiros registros)
precificacao.head()

# Gerando algumas estatísticas da base de dados
# a função describe mostra a quantidade de linhas; média; desvio padrão;
# valores mínimo e máximo; 1º e 3º quartil; mediana
precificacao.describe()

"""Verificamos, por exemplo, que o preço médio por noite em dólares é de $ 152,72, onde o usuário deve reservar em média 7 noites."""

# Verificando se existe algum valor nulo ou ausente, e contando quantos tem
precificacao.isna().sum()

# Vamos agora, verificar o tipo de cada variável
precificacao.info()

# Começando o tratamento dos dados ausentes
# Primeiro, vamos preencher o campo [nome], que é o nome do anúncio, com "Não especificado"
# A função fillna() é usada para preencher os valores faltantes na coluna especificada com o valor padrão desejado
# O argumento inplace=True faz com que as alterações sejam feitas diretamente no DataFrame original, sem a necessidade de atribuir o resultado de volta a uma variável.
precificacao['nome'].fillna("Não especificado", inplace=True)

# Seguimos a mesma abordagem para o campo [host_name], que é o nome do usuário anunciante.
precificacao['host_name'].fillna("Desconhecido", inplace=True)

# Para o campo [ultima_review], que contém a data da última revisão dada à listagem,
# Vamos preencher com uma data padrão, 1900-01-01, que representa uma data inicial
precificacao['ultima_review'].fillna("1900-01-01", inplace=True)

# Para o campo [reviews_por_mes], que contém o número de avaliações fornecidas por mês,
# Vamos preencher com 0
precificacao['reviews_por_mes'].fillna(0, inplace=True)

# O próximo passo é fazer uma análise de correlação entre as variáveis
# Correlação positiva: quando duas variáveis que possuem correlação crescem ou decrescem juntas, ou seja, possuem uma relação direta.
# Correlação negativa: quando duas variáveis possuem correlação mas quando uma variável cresce a outra decresce, ou vice-versa.

precificacao.corr(numeric_only=True)

# Agora, vamos fazer uma análise gráfica da correlação
# Para isso, criamos um gráfico de calor
# A variável annot serve para trazer os valores dentro do gráfico
correlacao = precificacao.corr(numeric_only=True)
sns.heatmap(correlacao, annot=True).set(title='Correlaçao entre variáveis numéricas')

"""# Questão 2

Responda também às seguintes perguntas:

## a.

Supondo que uma pessoa esteja pensando em investir em um apartamento para alugar na plataforma, onde seria mais indicada a compra?
"""

# Temos os campos [disponibilidade_365], que contém o número de dias em que o anúncio está disponível para reserva
# Ou seja, se a disponibilidade é alta, não deve haver muita procura nessa região
# E o campo [numero_de_reviews], que contém o número de comentários dados a cada listagem
# Ou seja, se há mais comentários, o local é mais procurado
# Então, devemos encontrar o primeiro bairro que ocorra de haver disponibilidade baixa e reviews altos

# Primeiro, calculamos a disponibilidade média de aluguel ao longo do ano para cada bairro
disponibilidade_media = precificacao.groupby('bairro')['disponibilidade_365'].mean()

# Ordenamos os bairros com base na disponibilidade média (do menor para o maior)
bairros_por_disponibilidade = disponibilidade_media.sort_values().index.tolist()

# Calculamos o número total de reviews para cada bairro
total_reviews = precificacao.groupby('bairro')['numero_de_reviews'].sum()

# Ordenamos os bairros com base no número total de reviews (do maior para o menor)
bairros_por_reviews = total_reviews.sort_values(ascending=False).index.tolist()

# Encontramos a primeira área que ocorre em ambas as listas
primeiro_bairro_com_ocorrencia_comum = next(bairro for bairro in bairros_por_disponibilidade if bairro in bairros_por_reviews)

# Encontramos o bairro correspondente à primeira área encontrada
bairro_group_correspondente = precificacao[precificacao['bairro'] == primeiro_bairro_com_ocorrencia_comum]['bairro_group'].iloc[0]


print(f"A área mais indicada para compra é {primeiro_bairro_com_ocorrencia_comum}, no bairro {bairro_group_correspondente}" )

"""## b

O número mínimo de noites e a disponibilidade ao longo do ano interferem no preço?

*Como podemos ver pelo mapa de calor feito na questão 1, a correlação entre o preço e o número mínimo de noites é de 0.043, ou seja, muito baixa. A correlação entre o preço e a disponibilidade é de 0.082, também muito baixa.
Logo, tais variáveis não interferem no preço.*

## c

Existe algum padrão no texto do nome do local para lugares de mais alto valor?
"""

# Vamos listar o campo [bairro] com base no maior [price] para o menor

# Ordenando o DataFrame com base no preço (price) em ordem decrescente
precificacao_sorted = precificacao.sort_values(by='price', ascending=False)

# Extraindo os bairros correspondentes
bairros_por_price = precificacao_sorted['bairro'].head(50).tolist()

# Imprimindo os bairros
print("Bairros ordenados com base no maior price para o menor price:")
for bairro in bairros_por_price:
    print(bairro)

"""*Percebemos que alguns bairros incluem a "localização geográfica" em seu nome, como em Upper West Side e East Harlem, fora isso, não há padrão*

# Questão 3

Explique como você faria a previsão do preço a partir dos dados. Quais variáveis e/ou suas transformações você utilizou e por quê? Qual tipo de problema estamos resolvendo (regressão, classificação)? Qual modelo melhor se aproxima dos dados e quais seus prós e contras? Qual medida de performance do modelo foi escolhida e por quê?

*Estamos resolvendo um problema de regressão, pois deseja-se prever um valor numérico, no caso o preço.*

*As variáveis que podemos considerar para prever o preço incluem [disponibilidade_365], [calculado_host_listings_count], e [reviews_por_mes], por exemplo, pois segundo o mapa de calor, são as variáveis de maior correlação com o preço, nessa ordem.*

*Para o caso da previsão dos preços, onde há várias variáveis independentes e pode haver relações não lineares entre essas variáveis e o preço, a regressão polinomial pode ser útil. No entanto, sua desvantagem é a questão do overfitting e a dificuldade na interpretação.*

*Caso a interpretação seja uma prioridade, e as relações entre as variáveis forem lineares, uma simples regressão linear pode ser útil, pois além de tudo é rápida no treinamento. No entanto, é sensível a outliers*

*Para avaliar o desempenho dos modelos de regressão, algumas medidas de desempenho podem ser consideradas, a depender do objetivo. Por exemplo, se o objetivo é minimizar os erros absolutos, o Erro Absoluto Médio (MAE) pode ser uma boa escolha.Se o objetivo é explicar a variabilidade nos dados, o Coeficiente de Determinação (R²) pode ser mais apropriado: um R² mais próximo de 1 indica um ajuste melhor do modelo aos dados, enquanto um R² mais próximo de 0 indica um ajuste pior.*
"""